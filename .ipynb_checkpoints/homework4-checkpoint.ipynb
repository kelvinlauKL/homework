{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e065dd-4be3-413d-866f-9d47b9a48851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['USER_AGENT'] = 'doge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ab7fa6-8c25-4620-abe7-81d5b9a75314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate OpenAI client\n",
    "!pip install -qU langchain_openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e407b1-326d-45ff-94c1-ed8479b1febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Wikipedia Article\n",
    "# Takes quite a bit of time due to the length of the Wiki article\n",
    "\n",
    "!pip install -qU langchain_community\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "# Can sometimes error stating no explicit parser was identified\n",
    "# Most likely an internal error with WikipediaLoader, since there \n",
    "# isn't any parameters that let you pass in a parser.\n",
    "docs = WikipediaLoader(\"Department_of_Government_Efficiency\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "558f9fd9-9144-46b3-8908-fc1c10cacd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the article into smaller chunks for better indexing\n",
    "!pip install -qU langchain\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63dfa350-f7ea-4c9f-8f85-5b5b6287c5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Inject splits into vector database\n",
    "!pip install -qU langchain_chroma\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "database = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = database.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8725d175-321a-4e99-8465-cce7431cb8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DOGE stands for the Department of Government Efficiency, officially the U.S. DOGE Service Temporary Organization. It is an initiative of the second Trump administration, informally led by Elon Musk, aimed at modernizing federal technology and implementing federal spending cuts and deregulation. The organization is set to conclude on July 4, 2026.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is DOGE?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c24798c-5e34-4afb-a114-ad02085cf38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vivek Ramaswamy was initially announced as a co-leader of DOGE alongside Elon Musk but stepped away from the project before it began. He did this to prepare for running for governor in Ohio. Therefore, he was not part of DOGE when it launched.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Was Vivek part of DOGE?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c93d6bf-a485-4f27-a408-bb6a3795f57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The retrieved context indicates that DOGE\\'s actions have led to significant controversy, including accusations of violating the U.S. Constitution and causing a potential constitutional crisis. Some Democratic members criticized DOGE for lacking authority, describing its actions as a \"takeover.\" Meanwhile, the White House and Republican Party defended DOGE and Musk, asserting that they are in full compliance with regulations.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What does the retrieved context say about DOGE's involvement with the US government?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daf2874a-2d17-4eb1-89ad-13f0156ed7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "keyword_retriever = BM25Retriever.from_documents(splits)\n",
    "keyword_retriever.k = 3\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[retriever, keyword_retriever], weights=[0.3, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3f977d5-fd2e-46ea-825c-719e0f5369e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2238201209.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[38], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    from :class:`~langchain_cohere import Cohere`\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# --- Cohere Contextual Compression Integration ---\n",
    "!pip install -qU langchain-cohere\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "from :class:`~langchain_cohere import Cohere`\n",
    "\n",
    "# Initialize Cohere LLM for compression (set temperature=0 for deterministic results)\n",
    "cohere_llm_for_compression = Cohere(temperature=0)\n",
    "# Instantiate the Cohere reranker compressor using the specified model\n",
    "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
    "\n",
    "# Wrap the ensemble retriever with the ContextualCompressionRetriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=ensemble_retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77bb3186-c427-4a2f-b1c5-46ff6ce0e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, ensemble_retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "091aa327-7e05-456b-91cf-79c249d93f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22c5882f-0bbe-4fb6-a122-983941726698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11d79c9b-7e3c-470e-9216-6ad56307cb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DOGE has been linked to Trump\\'s campaign promises regarding federal spending and efficiency, with proposals for a department aimed at streamlining government. Its actions have faced criticism for potentially violating the Constitution, leading to accusations of a \"takeover\" and raising conflict of interest concerns for Musk\\'s companies. The White House and Republican Party have defended DOGE and Musk, asserting compliance with government regulations.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What does the retrieved context say about DOGE in the US government?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"doge-session\"}\n",
    "    },\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59069bec-efba-48e8-929a-fced51db9589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three lawsuits had been filed in the United States District Court for the District of Columbia regarding DOGE as of January 21.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"How many lawsuits?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"doge-session\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424e4643-7467-4a5e-97e4-38363861cc77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
